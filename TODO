TODO

- dockerise + automate deployment
    - nginx serving html and client js, proxy request to node
    - node backend to interact with frontend and matching service
    - matching service api
    - single postgres database 
- deploy in EC2 AWS? (later do container based/serverless. rethink.)
- automate infra with Terra
- from backgorund task to redis+rq (so we can do more than 1)
    - do it lightweight. can we do threads and check their status?
- refactor (run multiple times, check error handling)
    - 1 smoke test for full system. 1 smoke test for each api E2E.
- double check SQL. we mighr have duplicates, currently using distinct as workaround
- deploy as containers AWS - closer to "serverless"
- store files in database on upload to have stateless node backend

https://genome.ucsc.edu/cgi-bin/hgTables?db=hg38&hgta_group=genes&hgta_track=refSeqComposite&hgta_table=ncbiRefSeqCurated&hgta_doSchema=describe+table+schema


HOW TO RUN:
uvicorn app:app 
yarn build && yarn run start
docker run --name x -e POSTGRES_PASSWORD= -e POSTGRES_USER= -e POSTGRES_DB= -p 5432:5432 -d postgres:14

DOWNLOAD GWAS: https://www.ebi.ac.uk/gwas/docs/file-download

\\\\\\\\\\\\\\\\\\\
POC:
User uploads a file (and a password?)
Gets a link to download the file when its ready

The backend receives the file
Process it (appends whatever is necessary)
Makes it available for download on the specified link (with a password?)
\\\\\\\\\\\\\\\\\\\




